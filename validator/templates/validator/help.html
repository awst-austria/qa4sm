{% extends 'common/base.html' %}

{% block content %}

<style type="text/css">
    .table .thead-dark th{
        color:white;
        background-color:#00AAE3;
        border-color:white
    }
</style>

<div style="text-align: left; max-width: 40rem; width: 100%; margin: auto;">
    <p>
        <a href="#validation">Validate Page</a><br/>
        <a href="#results_list">My Validations - Results List Page</a><br/>
        <a href="#results">Validation Results Page</a><br/>
        <a href="#publication">Publication</a><br/>
        <a href="#published">Published Validations Page</a><br/>
    </p>

    <a id="validation"></a>
    <h1 class="h3 mb-3 font-weight-normal">Validate Page</h1>

    <p>
        The validate page is subdivided into areas for the various validation parameters. Each area has
        menu with two icons on the top right. Hover over the question mark to get help for the respective areas. You can
        use the +/- icon to fold up or fold down the area.
    </p>
    <div style="display:flex;">
        <img class="scaled_image mb-3" src="../../static/images/help/menu_minus.png">
        <img class="scaled_image mb-3" src="../../static/images/help/menu_plus.png">
    </div>

    <p>
        <b>Step 1</b> - Choose the data you would like to validate - including the dataset name, the version of the dataset,
        and one of the soil moisture variables provided in the dataset. More details on the supported datasets can be found
        <a href="{% url 'datasets' %}#data">here</a>.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/data_set_selections.png">
    <p>
        <b>Step 2 [optional]</b> - Choose the criteria by which you would like to filter this dataset.
        The filters available depend on the data contained within the chosen dataset. For example,
        you can filter the C3S data to include only data with no inconsistencies detected (flag = 0).
        Details of the filter options provided for each dataset are given on the supported datasets page
        <a href="{% url 'datasets' %}">here</a>. You can also hover your mouse pointer over the question mark next to a filter
        to get a short explanation.
    </p>
    <p>
        <b>Step 3 [optional]</b> - If you want to intercompare several datasets, you can add more datasets to the validation
        using the <b>+</b> button, up to a maximum of five. Configure the settings for the additional datasets by selecting
        the respective tab and repeating steps 1 and 2 above. You can remove a dataset by clicking x on the active tab.<br/>
    </p>
    <p class="alert alert-info">
        <b>Intercomparison:</b> The intercomparison mode of QA4SM validates up to five satellite data sets against a common
        reference data set. For each reference location (e.g. each ISMN station) it finds the nearest observation series in
        all selected satellite products.
        All observations series are then scaled (if selected) and temporally matched to the reference series.
        For validation only the common time stamps (that are available in all satellite products) are used to calculate validation metrics
        between the reference and each individual satellite product.
        This way deviations in the metrics due to different temporal coverage are excluded and validation results represent differences in
        the performance of the compared satellite products.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/intercomparison.png">
    <p>
        <b>Step 4</b> - Choose the reference dataset you would like to use for the
        validation including the dataset name, the version of the dataset, and the soil moisture variables provided in
        the dataset. More details on the supported datasets can be found <a href="{% url 'datasets' %}#ref">here</a>.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/reference_data_set_selections.png">
    <p>
        <b>Step 5 [optional]</b> - Choose the criteria by which you would like to filter the reference data prior to
        running the validation. The filters available depend on the data contained within the chosen dataset. For example,
        you can filter the ISMN data to include only data points where the soil_moisture_flag is &quot;G&quot; for &quot;good&quot;. You can also choose particular
        networks and depth range at which the measurements have been done. To do that you have to open an appropriate window by clicking a 'select...'
        link next to the filter you want to parameterised.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/networks.png">
    <p>
        The window for choosing networks contains a list of continents. When clicking a continent name a list of networks that belong to the continent folds down.
        Next to each network there is a name of the country that the network belongs to given. To toggle the particular network it is enough to click on its name.
        The choice has to be approved clicking the 'Use networks' button.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/depths.png">
    <p>
        The window for the depth selection contains two fields for introducing the depth range. Again, the choice has to be accepted clicking the 'Use depth range' button.
        <br>
        <br>
        Details of the filter options provided for each dataset are given on the supported datasets page
        <a href="{% url 'datasets' %}">here</a>. You can also hover your mouse pointer over the question mark next to a filter
        to get a short explanation.
    </p>
    <p>
        <b>Step 6 [optional]</b> - If you want to calculate metrics from anomalies instead of absolute values, select the desired method
        in the &quot;Method&quot; drop-down menu. The options are:
    </p>
    <ul>
        <li>Do not calculate: don't calculate anomalies, use absolute values.</li>
        <li>35 day moving average: calculate the differences between each measurement value and the 35 day moving average around the value.</li>
        <li>Climatology: calculate the differences between each measurement value and the climatology value for that day of the year. The climatology
        is calculated producing an average for each day of the year across the input dataset over the given climatology period. You have to specify
        which years to use for climatology calculation.</li>
    </ul>
    <img class="scaled_image mb-3" src="../../static/images/help/anomalies.png">
    <p>
        <b>Step 7 [optional]</b> - Chose the geographic area over which the validation should be performed. You can either specify a lat/lon bounding
        box directly or you can select the area on a map by clicking the globe button. The trash button will clear all four bounding
        box fields.<br/>
        If you don't specify an area, a global validation will be done.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/spatial_subsetting.png">
    <img class="scaled_image mb-3" src="../../static/images/help/map_selection.png">
    <p>
        <b>Step 8 [optional]</b> - Choose the date range over which the validation should be performed. Accepted formats are: YYYY*MM*DD
        or DD*MM*YYYY where * can be any of &quot;.&quot;, &quot;/&quot; or &quot;-&quot;. It is also possible to choose a date from a calendar, available under the calendar button.
        By default, the date range is determined through temporal matching of the data and reference selected.
        If you leave validation period fields empty, the default date range will be used.  For the time range
        covered by the various datasets, see the <a href="{% url 'datasets' %}">datasets page</a>.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/validation_period.png">

    <p>
        <b>Step 9 [optional]</b> - Activate Triple Collocation Analysis (TC). By default, QA4SM calculates validation
        metrics between dataset pairs (the reference and each candidate data set). If more than 3 datasets
        are selected (including the reference), the switch to activate TC becomes available. If
        TC is selected, in addition to the basic metrics between dataset pairs, TC metrics between
        triples of selected datasets are calculated. The reference is included in all triples and
        metrics are found for all candidate datasets. Note that each TC metric is specific to a dataset
        (this is evident from the metric name). TC metrics are affected by all 3 used datasets. Only results from TC with
        independent datasets should be used.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/tca.png">

    <p>
        <b>Step 10</b> - Choose how the data (or reference) will be scaled before metrics calculation.
        The data can be scaled to the reference (default) or vice versa.
        Note that in an intercomparision validation (with multiple datasets), only scaling to reference
        is possible.
        The scaling method determines how values of one dataset are mapped onto the value range of the
        other dataset for better comparability.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/scaling.png">

    <p>
        <b>Step 11 [optional]</b> - Name your validation results to make it easier to identify it in the list of all your validations.
        Note that it is possible to change the name later, unless the validation has been published.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/name_your_validation.png">

    <p>
        <b>Step 12</b> - Run the validation process. You'll be notified via e-mail once it's
        finished. You don't need to keep the results window (or even your browser) open for
        the validation to run. The email will contain a link to your results.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/validate_button.png">

    <a id="results_list"></a>
    <h1 id="help3" class="h3 mb-3 font-weight-normal">My Validations - Results List Page</h1>

    <p>
        The list shows all your validations, including the currently running ones, sorted by default by date (latest first).
        It is possible to sort the list according to the validation name, date, status and the dataset used as the reference.
        Apart from the validations run by the particular user, there can be also listed published validations that are tracked by the user.
    </p>

    <img class="scaled_image mb-3" src="../../static/images/help/my_validations.png">

    <p>
        <i>Note:</i> Your validations will be automatically removed {{ expiry_period }} days after completion by our
        auto-cleanup process, unless you extend or archive them. You will be warned via email about validation expiry
        {{ warning_period }} days before deletion.
    </p>

    <p>
        The icons in the validations' title bars indicate the following:
    </p>

    <ul>
        <li>
            <span class="fas fa-ban"></span> The validation was cancelled.
        </li>
        <li>
            <span class="fas fa-running"></span> The validation is still running and has no results yet.
        </li>
        <li>
            <span class="fas fa-calendar-alt"></span> The validation has completed. It will be removed
            by the auto-cleanup process {{ expiry_period }} days after completion, unless you extend or archive it.
            You can see the expiration date by hovering your mouse over the icon.
        </li>
        <li>
            <span class="fas fa-archive"></span> The validation has been archived and won't be automatically removed
            by the cleanup process.
        </li>
        <li>
            <span class="fas fa-exclamation-triangle"></span> The validation will expire within the next
            {{ warning_period }} days and will then be removed by the auto-cleanup process, unless you extend or archive it.
            You can see the expiration date by hovering your mouse over the icon.
        </li>
    </ul>

    <p>
        The buttons on the right-hand side of each validation have the following effects:
    </p>

        <ul>
            <li>
                <span class="fas fa-folder-open"></span> You can access the <a href="#results">results details
                page</a> of a validation through its folder button.
            </li>
            <li>
                <span class="fas fa-stop"></span> The stop button is only visible while the validation is still
                running and allows you to abort it.
            </li>
            <li>
                <span class="fas fa-times"></span> The remove button is only visible once the validation has finished
                or was aborted and will permanently delete the result. The remove button next to a validation being tracked,
                only removes the validation from this list, but doesn't delete it.
            </li>
            <li>
                <span class="fas fa-download"></span> The download graphs button allows you to download all graphs
                produced for the validation (in png and svg formats) in a zip archive.
            </li>
            <li>
                <span class="fas fa-file-download"></span> The download NetCDF button  allows you to download the
                validation result (metrics computed).
            </li>

        <li>
            <span class="fas fa-calendar-plus"></span> With the extend lifespan button, you can reset the auto-cleanup
            period of a result and thus postpone its automatic removal. You can use this if you're not sure yet whether
            you want to keep it - you will have another {{ expiry_period }} days to decide and will be notified
            (again) before deletion.
        </li>
        <li>
            <span class="fas fa-archive"></span> With the archive button, you can exclude a validation from auto-cleanup
            and thus keep it indefinitely.
        </li>
        <li>
            <span class="fas fa-calendar-alt"></span> With the un-archive button, you can make a validation eligible for
            auto-cleanup again. It will be automatically extended, so you will have another {{ expiry_period }} days before
            deletion and will be notified (again).
        </li>
        <li>
            <span class="fas fa-redo"></span> With this button you can load settings of the particular validations; you will be redirected
            to the validate page.
        </li>
        </ul>
    </p>
<!--    <img class="scaled_image mb-3" src="../../static/images/help/my_validations.png">-->

    <a id="results"></a>
    <h1 class="h3 mb-3 font-weight-normal">Validation Results Page</h1>

    <p>
        Once the validation process is finished, you can see a summary of the validation run
        on the results page.
    </p>
    <img class="scaled_image mb-3" src="../../static/images/help/results_overview.png">

    <p>
        The buttons at the bottom of the result overview have the following effects:
    </p>

    <ul>
        <li>
            <span class="fas fa-times"></span> <span class="font-weight-bold">Remove</span> will permanently delete the result.
        </li>
        <li>
            <span class="fas fa-calendar-plus"></span> <span class="font-weight-bold">Renew</span> will reset the auto-cleanup
            period of a result and thus postpone its automatic removal. You can use this if you're not sure yet whether
            you want to keep it - you will have another {{ expiry_period }} days to decide and will be notified
            (again) before deletion.
        </li>
        <li>
            <span class="fas fa-archive"></span> <span class="font-weight-bold">Archive</span> will exclude a validation from auto-cleanup
            and thus keep it indefinitely.
        </li>
        <li>
            <span class="fas fa-calendar-alt"></span> <span class="font-weight-bold">Un-archive</span> will make a validation eligible for
            auto-cleanup again. It will be automatically extended, so you will have another {{ expiry_period }} days before
            deletion and will be notified (again).
        </li>
        <li>
            <span class="fas fa-book"></span> <span class="font-weight-bold">Publish</span> will publish the result NetCDF
            file to <a target="_blank" href="https://zenodo.org/">Zenodo</a>. This means the results can be cited
            with a <a target="_blank" href="https://www.doi.org/">DOI</a>. See section
            <a href="#publication">Publication</a> for details.
        </li>
    </ul>



    <p>
        The following metrics are calculated during the validation process:
    </p>

    <table class="table table-bordered mb-5">
        <thead class="thead-dark">
            <tr><th scope="col">Name</th> <th scope="col">Description</th></tr>
        </thead>
        <tbody>
            <tr><th scope="row">Pearson's r</th><td>Pearson correlation coefficient</td></tr>
            <tr><th scope="row">Pearson's r p-value</th><td>p-value for pearson correlation coefficient</td></tr>
            <tr><th scope="row">Spearman's rho</th><td>Spearman rank correlation coefficient</td></tr>
            <tr><th scope="row">Spearman's rho p-value</th><td>p-value for Spearman rank correlation coefficient</td></tr>
            <tr><th scope="row">Root-mean-square deviation</th><td>Root-mean-square deviation</td></tr>
            <tr><th scope="row">Bias (difference of means)</th><td>Average Error</td></tr>
            <tr><th scope="row"># observations</th><td>Number of Observations</td></tr>
            <tr><th scope="row">Unbiased root-mean-square deviation</th><td>Unbiased root-mean-square deviation</td></tr>
            <tr><th scope="row">Mean square error</th><td>Mean square error</td></tr>
            <tr><th scope="row">Mean square error correlation</th><td>Mean square error correlation</td></tr>
            <tr><th scope="row">Mean square error bias</th><td>Mean square error bias</td></tr>
            <tr><th scope="row">Mean square error variance</th><td>Mean square error variance</td></tr>
            <tr><th scope="row">Residual Sum of Squares</th><td>Residual Sum of Squares</td></tr>
            <tr><th scope="row">TC: Signal-to-noise ratio</th><td>TC: Signal-to-noise ratio</td></tr>
            <tr><th scope="row">TC: Error standard deviation</th><td>TC: Error standard deviation'</td></tr>
            <tr><th scope="row">TC: Scaling coefficient</th><td>TC: Scaling coefficient</td></tr>
        </tbody>
    </table>

    <p>
        Visualisations of these metrics are displayed in the <i>Result Files</i> section of the page: boxplots and geographical
        overview maps. You can select the metric shown with the left drop-down button below the graphs.<br/>
        For an intercomparison validation, all boxplots are combined into one graph. The dataset displayed in the overview
        map can be selected with the drop-down button on the right.
        <br/>
        You can also download a zipfile of all the plots in png and svg (vector) format by clicking on the <i>Download all
        graphs</i> button, and the result <a target="_blank" href="https://www.unidata.ucar.edu/software/netcdf/">NetCDF</a> file
        with all metrics with the <i>Download results in NetCDF</i> button.<br/>
    </p>
    <a id="results_graph"></a>
    <img class="scaled_image mb-3" src="../../static/images/help/results_graphs.png">

    <a id="publication"></a>
    <h2 class="h4 mb-3 font-weight-normal">Publication</h2>

    <p>
        This feature allows you to publish the result NetCDF file of your validation to
        <a target="_blank" href="https://zenodo.org/">Zenodo</a> under your own name but without creating your own
        Zenodo account. This gives you a <a target="_blank" href="https://www.doi.org/">DOI</a> for your results,
        which you can cite in your publications to give your readers open access to your data.
    </p>

    <img class="scaled_image mb-3" src="../../static/images/help/publication_dialog.png">

    <p>
        Once you click the <span class="font-weight-bold">Publish</span> button on the validation result page, you will
        be presented with a dialog
        containing the metadata the results will be published with. You can change the metadata to your liking (within
        some limits) and start the file upload to Zenodo by clicking <span class="font-weight-bold">Publish
        results</span>.<br/>
        Note that we require 'qa4sm' to be one of the keywords, and that Title, Description, Keywords, and
        Name are mandatory fields. You don't need to give an affiliation or
        <a href="https://orcid.org/" target="_blank">ORCID</a>, though. Changes you make to your
        author details will <span class="font-weight-bold">not</span> be stored to your user profile - for that, please
        got to the Profile page.<br/>
        The upload can take a few minutes, please be patient. If it should fail, please try
        again a few hours later. If it still doesn't work, please email us at {{admin_mail}} and include the error message
        you received.
    </p>

    <p>
        Please be aware that the NetCDF file and the metadata will be stored at Zenodo under the account of the QA4SM
        project but with your name as the author. Zenodo is a separate website run at CERN over which the QA4SM team
        has no control.<br/>
        <span class="font-weight-bold">Assigning a DOI to a result also means that it cannot easily be unpublished or
        deleted - see also <a href="https://help.zenodo.org/" target="_blank">Zenodo's FAQ</a>.</span><br/>

        If you prefer to use your own Zenodo account, you can of course do so - the QA4SM publication feature is just
        for convenience. Just download the NetCDF result file and upload it  yourself through Zenodo's submission process
        with your own account. We'd ask you to use 'qa4sm' as one of the keywords so that we can easily find all QA4SM
        results on Zenodo with a keyword search.
        <br/>

    </p>

    <a id="published"></a>
    <h1 id="help4" class="h3 mb-3 font-weight-normal">Published Validations Page</h1>

    <p>
        The list shows validations on the QA4SM service that have been published to
        <a target="_blank" href="https://zenodo.org/">Zenodo</a> by their owners. This means the results can be cited
        with a <a target="_blank" href="https://www.doi.org/">DOI</a>.
    </p>

    <p class="mt-5">If you want to email us to send comments, report errors, or ask questions, you can do so at {{admin_mail}}.</p>

    <a href="#">Back to top</a>

</div>

{% endblock %}
